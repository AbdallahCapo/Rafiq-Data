{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV35N96zluWo"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import re\n",
        "import logging\n",
        "import torch\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langdetect import detect\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, json_path: str):\n",
        "        self.json_path = json_path\n",
        "        self.qa_pairs: List[Tuple[str, str]] = []\n",
        "        self.instructions: List[str] = []\n",
        "\n",
        "    def load(self) -> Tuple[List[Tuple[str, str]], List[str]]:\n",
        "        try:\n",
        "            with open(self.json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                data = json.load(f)\n",
        "            self._parse_json(data)\n",
        "            return self.qa_pairs, self.instructions\n",
        "        except (FileNotFoundError, json.JSONDecodeError) as e:\n",
        "            logger.error(f\"Error loading JSON data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _parse_json(self, data: dict) -> None:\n",
        "        for category, content in data.items():\n",
        "            try:\n",
        "                if isinstance(content, list):\n",
        "                    for entry in content:\n",
        "                        if isinstance(entry, dict):\n",
        "                            question = entry.get(\"Q\") or entry.get(\"question\")\n",
        "                            answer = entry.get(\"A\") or entry.get(\"answer\")\n",
        "                            if isinstance(answer, list):\n",
        "                                answer = \" \".join(answer)\n",
        "                            if question and answer:\n",
        "                                self.qa_pairs.append((question, answer))\n",
        "                        elif isinstance(entry, list):\n",
        "                            for sub_entry in entry:\n",
        "                                question = sub_entry.get(\"question\")\n",
        "                                answer = sub_entry.get(\"answer\")\n",
        "                                if isinstance(answer, list):\n",
        "                                    answer = \" \".join(answer)\n",
        "                                if question and answer:\n",
        "                                    self.qa_pairs.append((question, answer))\n",
        "                        else:\n",
        "                            self.instructions.append(str(entry))\n",
        "                elif isinstance(content, dict):\n",
        "                    for value in content.values():\n",
        "                        if isinstance(value, dict):\n",
        "                            question = value.get(\"question\")\n",
        "                            answer = value.get(\"answer\")\n",
        "                            if isinstance(answer, list):\n",
        "                                answer = \" \".join(answer)\n",
        "                            if question and answer:\n",
        "                                self.qa_pairs.append((question, answer))\n",
        "                        elif isinstance(value, list):\n",
        "                            self.instructions.extend(value)\n",
        "                        else:\n",
        "                            self.instructions.append(str(value))\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error processing category '{category}': {e}\")\n",
        "\n",
        "        logger.info(f\"Loaded {len(self.qa_pairs)} Q&A pairs and {len(self.instructions)} instructions.\")\n",
        "\n",
        "\n",
        "class EmbeddingPipeline:\n",
        "    def __init__(self, qa_pairs: List[Tuple[str, str]], instructions: List[str]):\n",
        "        self.qa_pairs = qa_pairs\n",
        "        self.instructions = instructions\n",
        "        self.embedder = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "        self.index = None\n",
        "        self.all_data: List[Tuple[str, str]] = []\n",
        "\n",
        "    def build_index(self) -> None:\n",
        "        question_embeddings = self.embedder.encode([q[0] for q in self.qa_pairs])\n",
        "        instruction_embeddings = self.embedder.encode(self.instructions)\n",
        "\n",
        "        dimension = question_embeddings.shape[1]\n",
        "        self.index = faiss.IndexFlatL2(dimension)\n",
        "        self.index.add(np.array(question_embeddings))\n",
        "        self.index.add(np.array(instruction_embeddings))\n",
        "        self.all_data = self.qa_pairs + [(inst, inst) for inst in self.instructions]\n",
        "        logger.info(f\"FAISS index built with {len(self.all_data)} entries.\")\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 3, threshold: float = 0.7) -> List[str]:\n",
        "        try:\n",
        "            query_embedding = self.embedder.encode([query])\n",
        "            distances, indices = self.index.search(np.array(query_embedding), top_k)\n",
        "            return [self.all_data[idx][1] for dist, idx in zip(distances[0], indices[0]) if dist < threshold]\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error retrieving answer: {e}\")\n",
        "            return []\n",
        "\n",
        "\n",
        "class TextGenerator:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"CohereForAI/aya-expanse-8b\", timeout=600)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\"CohereForAI/aya-expanse-8b\", load_in_4bit=True, device_map=\"auto\")\n",
        "        self.pipeline = pipeline(\"text-generation\", model=self.model, tokenizer=self.tokenizer)\n",
        "\n",
        "    def generate(self, prompt: str, min_length: int, max_length: int) -> str:\n",
        "        try:\n",
        "            outputs = self.pipeline(\n",
        "                prompt,\n",
        "                max_length=max_length,\n",
        "                min_length=min_length,\n",
        "                do_sample=True,\n",
        "                top_p=0.85,\n",
        "                temperature=0.7,\n",
        "                eos_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "            return outputs[0]['generated_text'].replace(prompt, \"\").strip()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating text: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "\n",
        "class ChatbotPipeline:\n",
        "    def __init__(self, json_path: str):\n",
        "        data_loader = DataLoader(json_path)\n",
        "        qa_pairs, instructions = data_loader.load()\n",
        "\n",
        "        self.user_conversations: Dict[str, List[str]] = {}\n",
        "        self.embedding = EmbeddingPipeline(qa_pairs, instructions)\n",
        "        self.embedding.build_index()\n",
        "        self.generator = TextGenerator()\n",
        "\n",
        "    def get_dynamic_word_range(self, user_input: str, retrieved_answers: List[str]) -> Tuple[int, int]:\n",
        "        try:\n",
        "            language = detect(user_input)\n",
        "        except:\n",
        "            language = \"en\"\n",
        "\n",
        "        num_retrieved = sum(len(ans.split()) for ans in retrieved_answers)\n",
        "        avg_len = num_retrieved + len(user_input.split())\n",
        "\n",
        "        language_factors = {\n",
        "            \"en\": 1.0, \"ar\": 0.8, \"fr\": 1.1, \"zh\": 0.5, \"es\": 1.05,\n",
        "            \"de\": 1.0, \"ru\": 1.1, \"it\": 1.0, \"pt\": 1.05, \"ja\": 0.6, \"ko\": 0.7, \"tr\": 0.9\n",
        "        }\n",
        "        factor = language_factors.get(language, 1.0)\n",
        "\n",
        "        base_max_len = int((avg_len + 30) * factor)\n",
        "        return max(150, base_max_len - 100), max(500, base_max_len + 200)\n",
        "\n",
        "    def format_response(self, text: str) -> str:\n",
        "        text = re.sub(r\"<\\|im_end\\|>|<\\|endoftext\\|>\", \"\", text).strip()\n",
        "        text = re.sub(r\"\\n\", \"\", text).strip()\n",
        "        paragraphs = text.split(\"\\n\")\n",
        "        lines = []\n",
        "        for paragraph in paragraphs:\n",
        "            line = \"\"\n",
        "            for word in paragraph.split():\n",
        "                if len(line) + len(word) > 90:\n",
        "                    lines.append(line.strip())\n",
        "                    line = \"\"\n",
        "                line += f\"{word} \"\n",
        "            if line:\n",
        "                lines.append(line.strip())\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def add_bullets(self, text: str) -> str:\n",
        "        lines = text.split(\"\\n\")\n",
        "        return \"\\n\".join([f\"- {line.strip()}\" if re.match(r\"^\\d+\\.|^-\", line) else line for line in lines])\n",
        "\n",
        "    def clear_conclusion(self, text: str) -> str:\n",
        "        lines = text.split(\"\\n\")\n",
        "        if lines:\n",
        "            for phrase in [\"Conclusion:\", \"Summary:\", \"Final Thoughts:\"]:\n",
        "                if lines[-1].startswith(phrase):\n",
        "                    lines[-1] = lines[-1][len(phrase):].strip()\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def generate_response(self, user_id: str, user_input: str) -> str:\n",
        "        if user_id not in self.user_conversations:\n",
        "            self.user_conversations[user_id] = []\n",
        "\n",
        "        self.user_conversations[user_id].append(f\"User: {user_input}\")\n",
        "        retrieved_answers = self.embedding.retrieve(user_input)\n",
        "\n",
        "        if retrieved_answers and len(retrieved_answers[0].split()) < 50:\n",
        "            response = retrieved_answers[0]\n",
        "        else:\n",
        "            context = \" \".join(retrieved_answers[:2]) if retrieved_answers else \"\"\n",
        "            min_chars, max_chars = self.get_dynamic_word_range(user_input, retrieved_answers)\n",
        "            history = \"\\n\".join(self.user_conversations[user_id][-5:])\n",
        "\n",
        "            prompt = f\"\"\"\n",
        "            You are an AI assistant specialized in answering questions.\n",
        "            - Use provided context when available.\n",
        "            - Ensure responses are **detailed but concise**.\n",
        "            - Use **bullet points** when listing details.\n",
        "            - Do not repeat information unnecessarily.\n",
        "            - Maintain a **conversational tone**.\n",
        "\n",
        "            {'Context: ' + context if context else 'No specific context available.'}\n",
        "\n",
        "            Conversation history:\n",
        "            {history}\n",
        "\n",
        "            User question: {user_input}\n",
        "            Answer:\n",
        "            \"\"\"\n",
        "\n",
        "            response = self.generator.generate(prompt, min_chars, max_chars)\n",
        "            response = self.format_response(response)\n",
        "            response = self.add_bullets(response)\n",
        "            response = self.clear_conclusion(response)\n",
        "\n",
        "        if response and response[-1] not in \".!?\":\n",
        "            response += \".\"\n",
        "\n",
        "        self.user_conversations[user_id].append(f\"Chatbot: {response}\")\n",
        "        return response\n",
        "    def start_chat(self, user_id: str = \"user1\") -> None:\n",
        "        print(\"Start chatting with the AI! Type 'exit' or 'quit' to stop.\\n\")\n",
        "        while True:\n",
        "            user_input = input(\"You: \")\n",
        "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "                print(\"Chat ended.\")\n",
        "                break\n",
        "            response = self.generate_response(user_id=user_id, user_input=user_input)\n",
        "            print(f\"Bot: {response}\\n\")\n",
        "\n"
      ]
    }
  ]
}